---
title: 'Statistical Computing and Simulation: Assignment 4'
author: |
  | Deparment of Statistics,\ NCCU  
  | 葉佐晨 \   \   高崇哲
  | \{112354016,112354020\}@nccu.edu.tw
date: "`r Sys.Date()`"
output: 
  pdf_document: 
    extra_dependencies:
      ctex: UTF8
  html_document:
    df_print: paged
editor_options:
  markdown:
    wrap: 72
---

# Statistical Computing and Simulation

## Assignment 4, Due May 17/2024

```{r include=FALSE}
library(readODS)
library(reshape2)
library(easynls)
# library(matlib)
library(pracma)
library(marqLevAlg)
library(knitr)
```

## Question 1

## Question 2

Try at least three different methods to find the estimates of B and C
for the Gompertz model, $\mu_x = BC^x, x>0$, using the Taiwan data in
2019-2021. You may count `nlminb`, `nls` or `opt` as one of the methods
(for replacing Newton's method). Also, similar to what we saw in the
class, discuss the influence of starting points to the number of
iterations. You may choose the male data or female data.

```{r 2.1, message=FALSE, warning=FALSE}
y3s2 <- read_ods("y3s2-00000.ods", skip = 3)

colnames(y3s2)[1:4] <- c("Y", "year", "gender", "total")
male <- unique(y3s2$gender)[3]

y3s2 <- y3s2[y3s2$gender %in% c(male) & y3s2$year %in% c(2019:2021), -c(1,3,4)]
colnames(y3s2) <- c("year", "0", "2", "7", 
                  "12", "17" , "22", "27", "32", "37",
                  "42", "47" , "52", "57", "62", "67",
                  "72", "77" , "82", "87", "92", "97", "100")

y3s2_p <- transform(y3s2, `67` = as.numeric(`67`), `100` = as.numeric(`100`))
kable(y3s2_p, digits = 1, caption = "Age Mortgage Rate in 2019-2021")

mr <- melt(y3s2, id = "year", variable.name = "age", value.name = "rate")
mr$age <- as.numeric(as.character(mr$age))
mr$rate <- as.numeric(mr$rate)
mr <- mr[mr$age != 0, ]
mr <- data.frame(x = mr$age, y = mr$rate/1000)
```

### Solution

#### Newton Method with nls

```{r 2.2}
md4 <- nls(y ~ b * c^x, data = mr,
           start = list(b = 0.1, c = 1))
plot(mr$x, log(mr$y),
     main = "Mortgage Rate and Gompertz Model with Newton Method",
     xlab = "age", ylab = "log(rate)")
lines(mr$x, log(predict(md4)))
```

#### Levenberg-Marquardt Method

```{r 2.3}
bc0 <- c(0.1, 1)
SSE <- function(y, x, bc){return(sum((y - (bc[1] * bc[2]^x))^2))}
estim <- marqLevAlg(bc0, fn = SSE, x = as.matrix(mr$x), y = mr$y)

pred.y <- log(estim$b[1] * estim$b[2]^mr$x)
plot(mr$x, log(mr$y),
     main = "Mortgage Rate and Gompertz Model with LM method",
     xlab = "age", ylab = "log(rate)")
lines(mr$x, pred.y)
```

#### Steepest Descent

```{r 2.4}
SSExy <- function(bc) {
  y <- mr$y
  x <- mr$x
  return(sum((y - (bc[1] * bc[2]^x))^2))
}
bc0 <- c(0.0001, 1.1)
stpd <- steep_descent(bc0, SSExy, maxiter = 1000)

pred.y <- log(stpd$xmin[1] * stpd$xmin[2]^mr$x)
plot(mr$x, log(mr$y),
     main = "Mortgage Rate and Gompertz Model with Steepest Descent",
     xlab = "age", ylab = "log(rate)")
lines(mr$x, pred.y)
```

#### Summary

```{r 2.5}
summary_est <- rbind(
  Newton = c(summary(md4)[["coefficients"]][,1], summary(md4)[["sigma"]], md4$convInfo[["finIter"]]),
  LM = c(estim$b, estim$fn.value, estim$ni),
  SteepDesc = c(stpd$xmin, stpd$fmin, stpd$niter)
)
colnames(summary_est) <- c("B.est", "C.est", "SSE", "iter")
kable(summary_est, digits = 5, caption = "Summary of three Methods of Optimization")
```

## Question 3

## Question 4

Evaluate the CDF of standard normal distribution $\Phi(x)$ using the
method of Important Sampling and other Variance Reduction Methods (at
least two different methods). Consider
$x = −6, −5, −4, −3.5, −3, −2.5, −2$.

### Solution

```{r 4.1}
ImportantSample <- function(x, n){
  u <- runif(n)
  y <- - (sqrt(3)/pi) * log((1 + exp(-pi*x/sqrt(3))) / u - 1)
  gy <- (pi * exp(-pi*y/sqrt(3))) / (sqrt(3) * (1 + exp(-pi*y/sqrt(3)))^2)
  phiy <- dnorm(y)
  est <- ((1/n) / (1 + exp(-pi*x/sqrt(3)))) * sum(phiy / gy)
  return(est)
}

MCInteg <- function(x, n){
  u <- runif(n, 1/x, 0)
  y <- (1 / (sqrt(2*pi))) * exp(-1/(2*u^2)) / (abs(x)*u^2)
  est <- sum(y) / n
  return(est)
}
```

#### Important Sampling

```{r 4.2}
x <- c(-6, -5, -4, -3.5, -3, -2.5, -2)
n <- c(100, 1000, 5000)
res_is <- outer(x, n, Vectorize(function(x, n){ImportantSample(x = x, n = n)}))

res_is <- cbind(res_is, pnorm(x))
dimnames(res_is) <- list(paste0("x=", x), c(paste0("n=", n), "pnorm"))

kable(res_is, digits = 10, caption = "Estimates with Important Sampling")
```

#### Monte Carlo Integration

```{r 4.3}
x <- c(-6, -5, -4, -3.5, -3, -2.5, -2)
n <- c(100, 1000, 5000)
res_mci <- outer(x, n, Vectorize(function(x, n){MCInteg(x = x, n = n)}))

res_mci <- cbind(res_mci, pnorm(x))
dimnames(res_mci) <- list(paste0("x=", x), c(paste0("n=", n), "pnorm"))

kable(res_mci, digits = 10, caption = "Estimates with Monte-Carlo Integration")
```

## Question 5

## Question 6

Let $X_i, i=1,\cdots,5$ be random variables, following the exponential
distribution with mean 1. Consider the quantity $\theta$ defined by
$$\theta=P\left(\sum_{i=1}^5iX_i \geq 21.6\right)$$. Propose at least
three simulation methods to estimate $\theta$ and compare their
variances.

### Solution

Because $X_i$'s are from exponential distribution with $\lambda=1$, the
statistic $\sum_{i=1}^5iX_i$'s expectation is
$$E\left(\sum_{i=1}^5iX_i\right) = \sum_{i=1}^5iE(X_i) = \sum_{i=1}^5i = 15$$
and variance is
$$Var\left(\sum_{i=1}^5iX_i\right) = \sum_{i=1}^5i^2Var(X_i) = \sum_{i=1}^5i^2 = 55$$
So considering Central Limit Theorem,
$$\frac{\sum_{i=1}^5iX_i - E\left(\sum_{i=1}^5iX_i\right)}{\sqrt{Var\left(\sum_{i=1}^5iX_i\right)}} \longrightarrow Z \sim N(0, 1) \text{, as } n \rightarrow \infty$$
Therefore,
$$\theta=P\left(\sum_{i=1}^5iX_i \geq 21.6\right) \longrightarrow P\left(Z \geq \frac{21.6 - 15}{55}\right) = P(Z \geq 0.89)$$
So we transform the problem of sum of exponential variables to standard
normal variable problem.

We perform 4 estimators of $\theta$.

1.  we direct sample from Normal distribution and use indicator function
    to specifies whether larger than 0.89

$$\hat{\theta}_1 = \frac{1}{n}\sum_{i=1}^nI(X_i \geq 0.89) \text{, where } X_i \sim N(0,1)$$

2.  Base on method 1, we use two side of sample to reduce the variance
    half
    $$\hat{\theta}_2 = \frac{1}{2n}\sum_{i=1}^nI(|X_i| \geq 0.89) \text{, where } X_i \sim N(0,1)$$

3.  Transform the normal variable to uniform variable
    $$1 - 2\theta = \int_{-0.89}^{0.89}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx=2\int_{0}^{0.89}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx$$
    $$2\theta=1-2\cdot0.89\int_{0}^{0.89}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}\frac{1}{0.89}dx \text{, where }X \sim U(0, 0.89)$$
    $$\hat{\theta}_3 = \frac{1}{2} - \frac{0.89}{n}\sum_{i=1}^n\frac{1}{\sqrt{2\pi}}e^{-\frac{X_i^2}{2}}\text{, where }X_i \sim U(0, 0.89)$$

4.  Base on method 3, we transform $X$ to $\frac{1}{Y}$. So
    $$\theta = \int_{-\infty}^{-0.89}\frac{1}{\sqrt{2\pi}}e^{-\frac{x^2}{2}}dx=\frac{1}{0.89}\int_{-\frac{1}{0.89}}^0\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2y^2}}\left|{\frac{1}{y^2}}\right|0.89dy \text{, where } Y \sim U\left(\frac{1}{0.89}, 0\right)$$

$$\hat{\theta}_4 =  \frac{1}{0.89n}\sum_{i=1}^n\frac{1}{\sqrt{2\pi}}e^{-\frac{1}{2Y_i^2}}\text{, where } Y_i \sim U\left(\frac{1}{0.89}, 0\right)$$

```{r 6.1}
lambda <- 1
num <- 5
critical <- 21.6

mean_s <- sum(seq(1, num))
var_s <- sum((seq(1, num))^2)
sd_s <- sqrt(var_s)
std_c <- (critical - mean_s) / sd_s

# 4 methods to generate estimate of theta
Rtheta1 <- function(n, std_c){
  sum(rnorm(n) > std_c) / n
}

Rtheta2 <- function(n, std_c){
  sum(abs(rnorm(n)) > std_c) / (2*n)
}

Rtheta3 <- function(n, std_c){
  u <- runif(n, min = 0, max = std_c)
  0.5*(1 - sum(2 * std_c * (1 / sqrt(2*pi)) * exp(-(u^2) / 2)) / n)
}

Rtheta4 <- function(n, std_c){
  y <- runif(n, min = 0, max = 1/std_c)
  sum((1 / std_c) * (1 / sqrt(2*pi)) * exp(-1 / (2*y^2)) / (y^2)) / n
}

# function that perform Rtheta simulation 1000 times
EstTheta <- function(Rtheta, n, std_c, time = 1000, var = TRUE){
  ests <- replicate(time, Rtheta(n, std_c))
  if (var == TRUE){
    return(sd(ests))
  }else{
    return(mean(ests))
  }
}

Rtheta_list <- c(rtheta1=Rtheta1, rtheta2=Rtheta2, rtheta3=Rtheta3, rtheta4=Rtheta4)
n <- c(100, 1000, 5000)
```

#### Mean of Estimate

```{r 6.2}
mean_est <- outer(n, Rtheta_list, 
      Vectorize(function(n, Rtheta){EstTheta(Rtheta, n = n, std_c = std_c, var = FALSE)}))
dimnames(mean_est) <- list(paste0("N=", n), paste("method", 1:4))
kable(mean_est, digits = 4, caption = "Mean of Estimates")
```

#### Standard Deviation of Estimate

```{r 6.3}
sd_est <- outer(n, Rtheta_list,
                Vectorize(function(n, Rtheta){EstTheta(Rtheta, n = n, std_c = std_c)}))
dimnames(sd_est) <- list(paste0("N=", n), paste("method", 1:4))
kable(sd_est, digits = 4, caption = "Standard Deviation of Estimates")
```

## Appendix

### R code

### question 1

```{r ref.label=c("1.1", "1.2", "1.3", "1.4"), echo=TRUE, eval=FALSE}
```

### question 2

```{r ref.label=c("2.1", "2.2", "2.3", "2.4", "2.5"), echo=TRUE, eval=FALSE}
```

### question 3

```{r ref.label=c("3.1", "3.2", "3.3", "3.4", "3.5", "3.6"), echo=TRUE, eval=FALSE}
```

### question 4

```{r ref.label=c("4.1", "4.2", "4.3"), echo=TRUE, eval=FALSE}
```

### question 5

```{r ref.label=c("5.1", "5.2", "5.3", "5.4"), echo=TRUE, eval=FALSE}
```

### question 6

```{r ref.label=c("6.1", "6.2", "6.3"), echo=TRUE, eval=FALSE}
```
